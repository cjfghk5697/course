<FrameworkSwitchCourse {fw} />

# 사전학 모델 사용하기[[using-pretrained-models]]
          
{#if fw === 'pt'}

<CourseFloatingBanner chapter={4}
  classNames="absolute z-10 right-0 top-0"
  notebooks={[
    {label: "Google Colab", value: "https://colab.research.google.com/github/huggingface/notebooks/blob/master/course/en/chapter4/section2_pt.ipynb"},
    {label: "Aws Studio", value: "https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/master/course/en/chapter4/section2_pt.ipynb"},
]} />

{:else}

<CourseFloatingBanner chapter={4}
  classNames="absolute z-10 right-0 top-0"
  notebooks={[
    {label: "Google Colab", value: "https://colab.research.google.com/github/huggingface/notebooks/blob/master/course/en/chapter4/section2_tf.ipynb"},
    {label: "Aws Studio", value: "https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/master/course/en/chapter4/section2_tf.ipynb"},
]} />

{/if}

Model Hub는 적절한 모델을 선택하는 과정을 간단하게 만들어주어, 이를 다양한 라이브러리에서 몇 줄의 코드로 사용할 수 있게 해줍니다. 이제 실제로 이러한 모델을 사용하는 방법과 커뮤니티에 기여하는 방법을 살펴보겠습니다.

예시로 프랑스어 기반의 마스크 채우기(mask filling) 모델을 찾아봅시다.
<div class="flex justify-center">
<img src="https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter4/camembert.gif" alt="Selecting the Camembert model." width="80%"/>
</div>

`camembert-base` 체크포인트를 선택하여 사용해보겠습니다. `camembert-base`라는 식별자만 있으면 이를 사용하기 시작할 수 있습니다! 이전 챕터에서 보았듯이, `pipeline()` 함수를 사용하여 이를 인스턴스화할 수 있습니다:
```py
from transformers import pipeline

camembert_fill_mask = pipeline("fill-mask", model="camembert-base")
results = camembert_fill_mask("Le camembert est <mask> :)")
```

```python out
[
  {'sequence': 'Le camembert est délicieux :)', 'score': 0.49091005325317383, 'token': 7200, 'token_str': 'délicieux'}, 
  {'sequence': 'Le camembert est excellent :)', 'score': 0.1055697426199913, 'token': 2183, 'token_str': 'excellent'}, 
  {'sequence': 'Le camembert est succulent :)', 'score': 0.03453313186764717, 'token': 26202, 'token_str': 'succulent'}, 
  {'sequence': 'Le camembert est meilleur :)', 'score': 0.0330314114689827, 'token': 528, 'token_str': 'meilleur'}, 
  {'sequence': 'Le camembert est parfait :)', 'score': 0.03007650189101696, 'token': 1654, 'token_str': 'parfait'}
]
```

보시다시피, 파이프라인 내에서 모델을 로드하는 것은 매우 간단합니다. 주의해야 할 점은 선택한 체크포인트가 하고자하는 작업에 적합한지 확인하는 것입니다. 예를 들어, 여기서는 `camembert-base` 체크포인트를 `fill-mask` 파이프라인에 가져오고 있는데, 이는 전혀 문제가 없습니다. 하지만 이 체크포인트를 `text-classification` 파이프라인에 가져오면 결과물은 아무 의미 없을 것입니다. 왜냐하면 `camembert-base`의 헤드가 이 작업에 맞지 않기 때문입니다! Hugging Face Hub 인터페이스에서 작업 선택기를 사용하여 적절한 체크포인트를 선택하는 것을 추천합니다:

<div class="flex justify-center">
<img src="https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter4/tasks.png" alt="The task selector on the web interface." width="80%"/>
</div>

모델 아키텍처를 직접 사용하여 체크포인트를 인스턴스화할 수도 있습니다:

{#if fw === 'pt'}
```py
from transformers import CamembertTokenizer, CamembertForMaskedLM

tokenizer = CamembertTokenizer.from_pretrained("camembert-base")
model = CamembertForMaskedLM.from_pretrained("camembert-base")
```

하지만 [Auto* 클래스](https://huggingface.co/transformers/model_doc/auto?highlight=auto#auto-classes)를 사용하는 것을 권장합니다. 이 클래스들은 설계상 아키텍처에 구애받지 않기 때문입니다. 이전 코드 샘플은 사용자가 CamemBERT 아키텍처로 로드 가능한 체크포인트에만 한정되지만, `Auto*` 클래스를 사용하면 체크포인트 전환이 간단해집니다:

```py
from transformers import AutoTokenizer, AutoModelForMaskedLM

tokenizer = AutoTokenizer.from_pretrained("camembert-base")
model = AutoModelForMaskedLM.from_pretrained("camembert-base")
```
{:else}
```py
from transformers import CamembertTokenizer, TFCamembertForMaskedLM

tokenizer = CamembertTokenizer.from_pretrained("camembert-base")
model = TFCamembertForMaskedLM.from_pretrained("camembert-base")
```

하지만 [TFAuto* 클래스](https://huggingface.co/transformers/model_doc/auto?highlight=auto#auto-classes)를 사용하는 것을 권장합니다. 이 클래스들은 설계상 아키텍처에 구애받지 않기 때문입니다. 이전 코드 샘플은 사용자가 CamemBERT 아키텍처로 로드 가능한 체크포인트에만 한정되지만, `TFAuto*` 클래스를 사용하면 체크포인트 전환이 간단해집니다:

```py
from transformers import AutoTokenizer, TFAutoModelForMaskedLM

tokenizer = AutoTokenizer.from_pretrained("camembert-base")
model = TFAutoModelForMaskedLM.from_pretrained("camembert-base")
```
{/if}

<Tip>
사전 학습 모델을 사용할 때는 모델이 어떻게 훈련되었는지, 어떤 데이터셋에서 훈련되었는지, 한계와 편향이 무엇인지 반드시 확인하세요. 이러한 정보는 모델 카드에 기재되어 있습니다.
</Tip>
